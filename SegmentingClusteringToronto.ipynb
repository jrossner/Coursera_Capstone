{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Segmenting and Clustering Neighborhoods in Toronto"}, {"metadata": {}, "cell_type": "markdown", "source": "## Part 1"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Getting import packages and functions"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Solving environment: | ", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Here we download the wikipedia data set using pandas"}, {"metadata": {}, "cell_type": "code", "source": "url = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "data = pd.read_html(url)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### And convert it to a pandas data frame"}, {"metadata": {}, "cell_type": "code", "source": "t_df = pd.DataFrame(data[0])\nt_df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Here we eliminate all rows with a \"Not assigned\" Burough"}, {"metadata": {}, "cell_type": "code", "source": "df = t_df[t_df.Borough != \"Not assigned\"]\ndf.head(10)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### And here we see that there are no cases of a row where the Burough is named but the Neighborhood is not"}, {"metadata": {}, "cell_type": "code", "source": "df[df.Neighborhood == \"Not assigned\"]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we check our shape..."}, {"metadata": {}, "cell_type": "code", "source": "df.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Our resulting data set has 3 columns and 103 observations!"}, {"metadata": {}, "cell_type": "markdown", "source": "## Part 2"}, {"metadata": {}, "cell_type": "markdown", "source": "#### importing geocoder to get coordinates"}, {"metadata": {}, "cell_type": "code", "source": "#!conda install -c conda-forge geocoder=1.38.1 --yes\n#import geocoder\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### set up empty Latitude and Longitude columns in df"}, {"metadata": {}, "cell_type": "code", "source": "df[\"Latitude\"] = np.NaN\ndf[\"Longitude\"] = np.NaN\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### find the coordinates for each Postal Code"}, {"metadata": {}, "cell_type": "code", "source": "#geolocator = Nominatim(user_agent=\"toronto_explorer\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#for i in df[\"Postal Code\"]:\n    #initialize your variable to None\n    #lat_lng_coords = None\n\n    # loop until you get the coordinates\n    #while(lat_lng_coords is None):\n      #g = geocoder.google('{}, Toronto, Ontario'.format(i))\n      #lat_lng_coords = g.latlng\n        \n    #latitude = lat_lng_coords[0]\n    #longitude = lat_lng_coords[1]\n    \n    #df.loc[df[\"Postal Code\"]==i,\"Latitude\"] = latitude\n    #df.loc[df[\"Postal Code\"]==i,\"Longitude\"] = longitude", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### geocoder not working (never finishes running, even on a single area code) so we dowload the csv"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "#geo_data = pd.read_csv(\"Geospatial_Coordinates.csv\")\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_c3184cd62a4c4b3a920f9b334b501109 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='idJWCKU3OzH7JulMLNlXo4IF5cXmOJOlxKqEWJYPLZis',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_c3184cd62a4c4b3a920f9b334b501109.get_object(Bucket='courseracapstoneapplieddatascienc-donotdelete-pr-whqbcsawpi7ucd',Key='Geospatial_Coordinates.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ngeo_data = pd.read_csv(body)\ngeo_data.head()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### We drop the Latitude and Longitude from our df and merge the df and geo_data by the postal code."}, {"metadata": {}, "cell_type": "code", "source": "df = df.drop(['Latitude', 'Longitude'], axis=1)\ndf_final = pd.merge(df, geo_data, on='Postal Code')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_final[df_final[\"Postal Code\"]==\"M5G\"]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### and we have recreate the section 2 dataframe"}, {"metadata": {}, "cell_type": "markdown", "source": "## Part 3"}, {"metadata": {}, "cell_type": "code", "source": "import requests", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "address = 'Toronto, Canada'\n\ngeolocator = Nominatim(user_agent=\"toronto_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Let's build a map of toronto with all of these neighborhoods in our dataset"}, {"metadata": {}, "cell_type": "code", "source": "map_toronto= folium.Map(location=[latitude, longitude],zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(df_final['Latitude'], df_final['Longitude'], df_final['Borough'], df_final['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we look at specifically toronto neighborhoods"}, {"metadata": {}, "cell_type": "code", "source": "toronto_data = df_final[df_final['Borough'].str.contains(\"Toronto\") == True].reset_index(drop=True)\ntoronto_data.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "CLIENT_ID = 'ZFPLKJUYQ4QRIQ54EXFUZIYTDJJMLA341EIHRQW3BTVWRKKU' # your Foursquare ID\nCLIENT_SECRET = 'GY5KRZEPMXPQAUSYE0KR50TF4Y1MGEECFDSWG5JA4LWC55IW' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Here's a function for getting the category of venue"}, {"metadata": {}, "cell_type": "code", "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### This function finds the names of venues within a 500 meter radius of our neighborhood coordinates"}, {"metadata": {}, "cell_type": "code", "source": "LIMIT = 100\n\ndef getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we can check out the names of the venues nearby"}, {"metadata": {}, "cell_type": "code", "source": "toronto_venues = getNearbyVenues(names=toronto_data['Neighborhood'],\n                                   latitudes=toronto_data['Latitude'],\n                                   longitudes=toronto_data['Longitude']\n                                  )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we code a dataset that uses indicator variables for venue type"}, {"metadata": {}, "cell_type": "code", "source": "# one hot encoding\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\n\ntoronto_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we can see which venue types are most frequent in each neighborhood"}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 5\n\nfor hood in toronto_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp =toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we find the 10 most common venues in each neighborhood"}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we cluster the nieghborhoods by similar venues"}, {"metadata": {}, "cell_type": "code", "source": "# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = toronto_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\ntoronto_merged.head() # check the last columns!", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### And here we map out the clusters"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Here we take a look at the first cluster of neighborhoods, by far largest cluster. The most common venues each neighborhood in this cluster has appears to be a Coffee Shop and Cafe."}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Now we look at the second cluster, which only has 3 neighborhoods in it. The most common venue for this cluster is a Park."}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### The other clusters displayed below only have a single neighborhood in each cluster"}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 4, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}